{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "616ce6c6",
   "metadata": {},
   "source": [
    "This notebook cleans and processes weather data of Manhattan from 2024 (the whole year). It starts with loading a raw CSV file with hourly weather observations, it drops the duplicate timestamps, chooses the columns of interest (e.g., temperature, humidity, wind speed), and changes the timestamps to Eastern Time. To guarantee uniformity in the timeframe, the notebook deletes the entries that are beyond 2024 upon conversion and estimates the final five hours of data by examining most recent trends. The resulting dataset is clean, comprehensive, and is utilised in our machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c24c356-36dd-48e2-8d5d-852ad9ac9959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing.\n",
    "import pandas as pd\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dbc40187-6f38-46a2-b871-66c6df2f77f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the CSV file.\n",
    "file_path = \"Manhattan_40_768517_-73_982194_1704067200_1735689599_684c94e349583b00082484e5.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3691fafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping duplicates based on 'dt_iso', keeping the first occurrence.\n",
    "df = df.drop_duplicates(subset='dt_iso', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5fde8f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count: 8784\n"
     ]
    }
   ],
   "source": [
    "# Getting row count.\n",
    "row_count = len(df)\n",
    "print(\"Row count:\", row_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90e35267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          dt_iso  temp  humidity  wind_speed  feels_like  \\\n",
      "0  2024-01-01 00:00:00 +0000 UTC  5.64        54        3.09        3.21   \n",
      "1  2024-01-01 01:00:00 +0000 UTC  5.77        53        3.60        3.04   \n",
      "2  2024-01-01 02:00:00 +0000 UTC  5.59        56        3.60        2.82   \n",
      "3  2024-01-01 03:00:00 +0000 UTC  5.75        58        3.60        3.01   \n",
      "4  2024-01-01 04:00:00 +0000 UTC  5.81        58        3.60        3.09   \n",
      "\n",
      "  weather_main  \n",
      "0       Clouds  \n",
      "1       Clouds  \n",
      "2       Clouds  \n",
      "3         Rain  \n",
      "4       Clouds  \n"
     ]
    }
   ],
   "source": [
    "# Keeping only the useful columns.\n",
    "df = df[['dt_iso', 'temp', 'humidity', 'wind_speed', 'feels_like', 'weather_main']]\n",
    "\n",
    "# Examining results.\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a827a4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   temp  humidity  wind_speed  feels_like weather_main        date  hour\n",
      "0  5.64        54        3.09        3.21       Clouds  2023-12-31    19\n",
      "1  5.77        53        3.60        3.04       Clouds  2023-12-31    20\n",
      "2  5.59        56        3.60        2.82       Clouds  2023-12-31    21\n",
      "3  5.75        58        3.60        3.01         Rain  2023-12-31    22\n",
      "4  5.81        58        3.60        3.09       Clouds  2023-12-31    23\n",
      "5  5.75        59        4.47        2.53         Rain  2024-01-01     0\n",
      "6  5.43        60        4.12        2.32         Rain  2024-01-01     1\n",
      "7  5.45        62        4.12        2.35       Clouds  2024-01-01     2\n",
      "8  5.05        64        4.12        1.85       Clouds  2024-01-01     3\n",
      "9  4.87        65        3.10        2.28       Clouds  2024-01-01     4\n"
     ]
    }
   ],
   "source": [
    "# Cleaning the string by removing ' +0000 UTC'.\n",
    "df['dt_iso'] = df['dt_iso'].str.replace(' +0000 UTC', '', regex=False)\n",
    "\n",
    "# Parsing as UTC time.\n",
    "df['dt_iso'] = pd.to_datetime(df['dt_iso'], format='%Y-%m-%d %H:%M:%S', utc=True)\n",
    "\n",
    "# Converting to Eastern Time (Manhattan).\n",
    "df['dt_iso'] = df['dt_iso'].dt.tz_convert('America/New_York')\n",
    "\n",
    "# Extracting date and hour.\n",
    "df['date'] = df['dt_iso'].dt.date\n",
    "df['hour'] = df['dt_iso'].dt.hour\n",
    "\n",
    "# Dropping dt_iso and rearranging.\n",
    "df = df.drop(columns=['dt_iso'])\n",
    "df = df[['temp', 'humidity', 'wind_speed', 'feels_like', 'weather_main', 'date', 'hour']]\n",
    "\n",
    "# Examining results.\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d53ac1",
   "metadata": {},
   "source": [
    "Since we're only using data from 2024, shifting the originally provided timestamps to Manhattan time caused them to move back by 5 hours. As a result, some data now falls into 2023 and needs to be removed. We’ll also need to infer the last five rows of data for 2024 to maintain continuity. I’ll do this next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "822460de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    temp  humidity  wind_speed  feels_like weather_main        date  hour\n",
      "5   5.75        59        4.47        2.53         Rain  2024-01-01     0\n",
      "6   5.43        60        4.12        2.32         Rain  2024-01-01     1\n",
      "7   5.45        62        4.12        2.35       Clouds  2024-01-01     2\n",
      "8   5.05        64        4.12        1.85       Clouds  2024-01-01     3\n",
      "9   4.87        65        3.10        2.28       Clouds  2024-01-01     4\n",
      "10  4.60        68        2.10        2.80       Clouds  2024-01-01     5\n",
      "11  4.74        70        3.60        1.78         Rain  2024-01-01     6\n",
      "12  3.92        78        3.60        0.78         Rain  2024-01-01     7\n",
      "13  3.94        81        2.68        1.49         Rain  2024-01-01     8\n",
      "14  4.22        80        2.60        1.89         Rain  2024-01-01     9\n"
     ]
    }
   ],
   "source": [
    "# Dropping rows where shifted datetime now falls into 2023.\n",
    "df = df[df['date'] >= pd.to_datetime('2024-01-01').date()]\n",
    "\n",
    "# Examining results.\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8067ddc3",
   "metadata": {},
   "source": [
    "Inferring the last five rows of data for 2024 below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "967799e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       temp  humidity  wind_speed  feels_like weather_main        date  hour\n",
      "8774  10.77      57.0        5.66        9.39        Clear  2024-12-31    14\n",
      "8775  10.78      59.0        6.17        9.45        Clear  2024-12-31    15\n",
      "8776  10.24      69.0        5.14        9.12        Clear  2024-12-31    16\n",
      "8777   9.87      70.0        5.14        7.37        Clear  2024-12-31    17\n",
      "8778   9.23      73.0        5.66        6.38        Clear  2024-12-31    18\n",
      "8779   8.84      77.8        5.97        5.73        Clear  2024-12-31    19\n",
      "8780   8.45      82.6        6.28        5.08        Clear  2024-12-31    20\n",
      "8781   8.05      87.4        6.58        4.42        Clear  2024-12-31    21\n",
      "8782   7.66      92.2        6.89        3.77        Clear  2024-12-31    22\n",
      "8783   7.27      97.0        7.20        3.12        Clear  2024-12-31    23\n"
     ]
    }
   ],
   "source": [
    "# Number of rows to forecast.\n",
    "n_forecast = 5\n",
    "\n",
    "# Using last 6 rows to compute average change per hour.\n",
    "df_last = df.tail(6).copy()\n",
    "deltas = df_last[['temp', 'humidity', 'wind_speed', 'feels_like']].diff().mean()\n",
    "\n",
    "last_row = df.iloc[-1].copy()\n",
    "new_rows = []\n",
    "for i in range(1, n_forecast + 1):\n",
    "    new_row = last_row.copy()\n",
    "    \n",
    "    # Applying results.\n",
    "    new_row['temp'] += deltas['temp']\n",
    "    new_row['humidity'] += deltas['humidity']\n",
    "    new_row['wind_speed'] += deltas['wind_speed']\n",
    "    new_row['feels_like'] += deltas['feels_like']\n",
    "    \n",
    "    # Handling hour/date increment.\n",
    "    new_hour = int(new_row['hour']) + 1\n",
    "    if new_hour > 23:\n",
    "        new_row['hour'] = 0\n",
    "        new_row['date'] = (pd.to_datetime(new_row['date']) + timedelta(days=1)).date()\n",
    "    else:\n",
    "        new_row['hour'] = new_hour\n",
    "\n",
    "    # Preserve last known weather condition\n",
    "    new_row['weather_main'] = last_row['weather_main']\n",
    "\n",
    "    # Appending and updating the last_row.\n",
    "    new_rows.append(new_row.copy())\n",
    "    last_row = new_row.copy()\n",
    "\n",
    "# Appending inferred rows to the original DataFrame.\n",
    "df = pd.concat([df, pd.DataFrame(new_rows)], ignore_index=True)\n",
    "\n",
    "# Rounding numerical columns to 2 decimal places.\n",
    "df[['temp', 'humidity', 'wind_speed', 'feels_like']] = df[['temp', 'humidity', 'wind_speed', 'feels_like']].round(2)\n",
    "\n",
    "# Examining results.\n",
    "print(df.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aabae73",
   "metadata": {},
   "source": [
    "I’ll now check for any missing combinations of date and hour, as we should have a complete set for all of 2024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4b1bd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 missing date and hour combination/s:\n",
      "         date  hour\n",
      "0  2024-03-10     2\n"
     ]
    }
   ],
   "source": [
    "# Getting date and hour combinations for 2024.\n",
    "all_dates = pd.date_range(start='2024-01-01', end='2024-12-31', freq='D')\n",
    "all_hours = list(range(24))\n",
    "\n",
    "# Creating full expected MultiIndex of date and hour.\n",
    "expected = pd.MultiIndex.from_product([all_dates.date, all_hours], names=['date', 'hour'])\n",
    "\n",
    "# Extracting current date and hour combinations.\n",
    "actual = pd.MultiIndex.from_frame(df[['date', 'hour']])\n",
    "\n",
    "# Finding missing combinations.\n",
    "missing = expected.difference(actual)\n",
    "\n",
    "# Examining results.\n",
    "if missing.empty:\n",
    "    print(\"No missing date and hour combinations!\")\n",
    "else:\n",
    "    print(f\"{len(missing)} missing date and hour combination/s:\")\n",
    "    print(missing.to_frame(index=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46119ab0",
   "metadata": {},
   "source": [
    "One hour is missing from the dataset (2024-03-10 02:00) due to Daylight Saving Time in New York. Clocks skip from 01:59 to 03:00, so 02:00 does not exist on that day. Hence, this is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e9a9ed8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Summary:\n",
      "  Expected rows (assuming 24/hr):   8784 (before DST adjustment)\n",
      "  Adjusted expected rows:           8783\n",
      "  Actual rows in DataFrame:         8784\n",
      "  Missing rows (due to DST):        1\n"
     ]
    }
   ],
   "source": [
    "# Total days in 2024.\n",
    "total_days = len(all_dates)  # 366 for leap year\n",
    "\n",
    "# Expected count.\n",
    "raw_expected_total = total_days * 24  # 8784\n",
    "\n",
    "# Adjusted expected count excluding DST gap.\n",
    "adjusted_expected_total = raw_expected_total - len(missing)\n",
    "\n",
    "# Actual count.\n",
    "actual_total = len(actual)\n",
    "\n",
    "# Displaying summary.\n",
    "print(\"Overall Summary:\")\n",
    "print(f\"  Expected rows (assuming 24/hr):   {raw_expected_total} (before DST adjustment)\")\n",
    "print(f\"  Adjusted expected rows:           {adjusted_expected_total}\")\n",
    "print(f\"  Actual rows in DataFrame:         {actual_total}\")\n",
    "print(f\"  Missing rows (due to DST):        {len(missing)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da340ca",
   "metadata": {},
   "source": [
    "There is a problem. The actual number of rows is 8784, but it should be 8783 after accounting for the 1 missing hour due to DST (2024-03-10 02:00). This suggests there may be a duplicate date and hour entry that should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52e4e96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 duplicate rows based on date and hour:\n",
      "      temp  humidity  wind_speed  feels_like weather_main        date  hour\n",
      "7368  8.61      57.0        4.63        6.01        Clear  2024-11-03     1\n",
      "7369  8.10      59.0        5.81        4.90        Clear  2024-11-03     1\n"
     ]
    }
   ],
   "source": [
    "# Checking for duplicate combinations of date and hour.\n",
    "duplicates = df[df.duplicated(subset=['date', 'hour'], keep=False)]\n",
    "\n",
    "# Examining results\n",
    "if duplicates.empty:\n",
    "    print(\"No duplicate date and hour combinations found.\")\n",
    "else:\n",
    "    print(f\"Found {len(duplicates)} duplicate rows based on date and hour:\")\n",
    "    print(duplicates.sort_values(['date', 'hour']).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87a1d20",
   "metadata": {},
   "source": [
    "On 2024-11-03, 1:00 AM occurs twice due to DST ending. Dropping one of the duplicate rows to maintain a consistent hourly time series for 2025 prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8999e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping the first row.\n",
    "df = df.drop_duplicates(subset=['date', 'hour'], keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c2cab1",
   "metadata": {},
   "source": [
    "Weather data is now clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "310dd544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to CSV file.\n",
    "df.to_csv('weather_2024_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
