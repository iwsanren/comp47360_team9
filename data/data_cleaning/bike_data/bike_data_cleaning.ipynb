{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c46d0c4",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ea88a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "# import geopandas as gpd\n",
    "# from shapely.geometry import Point\n",
    "# print(gpd.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28d9647",
   "metadata": {},
   "source": [
    "# data combine\n",
    "combine data from 2024.1-2024.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2df20f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: JC-202401-citibike-tripdata.csv.zip\n",
      "Processing: JC-202402-citibike-tripdata.csv.zip\n",
      "Processing: JC-202403-citibike-tripdata.csv.zip\n",
      "Processing: JC-202404-citibike-tripdata.csv.zip\n",
      "Processing: JC-202405-citibike-tripdata.csv.zip\n",
      "Processing: JC-202406-citibike-tripdata.csv.zip\n",
      "Processing: JC-202407-citibike-tripdata.csv.zip\n",
      "Processing: JC-202408-citibike-tripdata.csv.zip\n",
      "Processing: JC-202409-citibike-tripdata.csv.zip\n",
      "Processing: JC-202410-citibike-tripdata.csv.zip\n",
      "Processing: JC-202411-citibike-tripdata.csv.zip\n",
      "Processing: JC-202412-citibike-tripdata.csv.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'bike_2024_combined.csv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without checking datetime\n",
    "# Setting the data folder path\n",
    "data_folder = 'datasets'\n",
    "output_file = 'bike_2024_combined.csv'\n",
    "\n",
    "# Create an empty DataFrame for merging all data\n",
    "combined_df = pd.DataFrame()\n",
    "column_standard = None  # Used to standardize field names\n",
    "\n",
    "# Iterate over all zip files in the destination folder\n",
    "for file in sorted(os.listdir(data_folder)):\n",
    "    if file.startswith('JC-2024'):\n",
    "        if file.endswith('.zip') or file.endswith('.csv.zip'):\n",
    "            zip_path = os.path.join(data_folder, file)\n",
    "            print(f\"Processing: {file}\")\n",
    "\n",
    "            with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "                # Fetch the first csv file\n",
    "                csv_name = [f for f in z.namelist() if f.endswith('.csv')][0]\n",
    "                with z.open(csv_name) as f:\n",
    "                    df = pd.read_csv(f)\n",
    "\n",
    "                    # Initialize standard column names (only the first file is taken as a baseline) Take out the first csv file\n",
    "                    if column_standard is None:\n",
    "                        column_standard = df.columns.tolist()\n",
    "                    else:\n",
    "                        # Trying to rename inconsistent fields\n",
    "                        if set(df.columns) != set(column_standard):\n",
    "                            print(f\"Column mismatch in {file}\")\n",
    "                            continue\n",
    "\n",
    "                    combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "\n",
    "# Save the merged file\n",
    "combined_df.to_csv(output_file, index=False)\n",
    "output_file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5bca41",
   "metadata": {},
   "source": [
    "# Data clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82a31046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>rideable_type</th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lng</th>\n",
       "      <th>member_casual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0744109F13385D1D</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2024-01-15 15:18:07</td>\n",
       "      <td>2024-01-15 15:32:44</td>\n",
       "      <td>Morris Canal</td>\n",
       "      <td>JC072</td>\n",
       "      <td>Oakland Ave</td>\n",
       "      <td>JC022</td>\n",
       "      <td>40.712297</td>\n",
       "      <td>-74.038185</td>\n",
       "      <td>40.737604</td>\n",
       "      <td>-74.052478</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B1488BFEF9118000</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2024-01-13 15:32:50</td>\n",
       "      <td>2024-01-13 15:36:18</td>\n",
       "      <td>JC Medical Center</td>\n",
       "      <td>JC110</td>\n",
       "      <td>Grove St PATH</td>\n",
       "      <td>JC115</td>\n",
       "      <td>40.715391</td>\n",
       "      <td>-74.049692</td>\n",
       "      <td>40.719410</td>\n",
       "      <td>-74.043090</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95A2FE8E51B4C836</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2024-01-19 13:11:00</td>\n",
       "      <td>2024-01-19 13:14:44</td>\n",
       "      <td>Morris Canal</td>\n",
       "      <td>JC072</td>\n",
       "      <td>Exchange Pl</td>\n",
       "      <td>JC116</td>\n",
       "      <td>40.712419</td>\n",
       "      <td>-74.038526</td>\n",
       "      <td>40.716366</td>\n",
       "      <td>-74.034344</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95D9AFF6A1652DC1</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2024-01-23 07:03:49</td>\n",
       "      <td>2024-01-23 07:07:11</td>\n",
       "      <td>Morris Canal</td>\n",
       "      <td>JC072</td>\n",
       "      <td>Exchange Pl</td>\n",
       "      <td>JC116</td>\n",
       "      <td>40.712419</td>\n",
       "      <td>-74.038526</td>\n",
       "      <td>40.716366</td>\n",
       "      <td>-74.034344</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5F7408988A83B1B3</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2024-01-01 16:46:10</td>\n",
       "      <td>2024-01-01 16:50:31</td>\n",
       "      <td>Morris Canal</td>\n",
       "      <td>JC072</td>\n",
       "      <td>Harborside</td>\n",
       "      <td>JC104</td>\n",
       "      <td>40.712419</td>\n",
       "      <td>-74.038526</td>\n",
       "      <td>40.719252</td>\n",
       "      <td>-74.034234</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ride_id  rideable_type           started_at             ended_at  \\\n",
       "0  0744109F13385D1D  electric_bike  2024-01-15 15:18:07  2024-01-15 15:32:44   \n",
       "1  B1488BFEF9118000   classic_bike  2024-01-13 15:32:50  2024-01-13 15:36:18   \n",
       "2  95A2FE8E51B4C836   classic_bike  2024-01-19 13:11:00  2024-01-19 13:14:44   \n",
       "3  95D9AFF6A1652DC1   classic_bike  2024-01-23 07:03:49  2024-01-23 07:07:11   \n",
       "4  5F7408988A83B1B3   classic_bike  2024-01-01 16:46:10  2024-01-01 16:50:31   \n",
       "\n",
       "  start_station_name start_station_id end_station_name end_station_id  \\\n",
       "0       Morris Canal            JC072      Oakland Ave          JC022   \n",
       "1  JC Medical Center            JC110    Grove St PATH          JC115   \n",
       "2       Morris Canal            JC072      Exchange Pl          JC116   \n",
       "3       Morris Canal            JC072      Exchange Pl          JC116   \n",
       "4       Morris Canal            JC072       Harborside          JC104   \n",
       "\n",
       "   start_lat  start_lng    end_lat    end_lng member_casual  \n",
       "0  40.712297 -74.038185  40.737604 -74.052478        member  \n",
       "1  40.715391 -74.049692  40.719410 -74.043090        member  \n",
       "2  40.712419 -74.038526  40.716366 -74.034344        member  \n",
       "3  40.712419 -74.038526  40.716366 -74.034344        member  \n",
       "4  40.712419 -74.038526  40.719252 -74.034234        member  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"bike_2024_combined.csv\", parse_dates=False) # Avoid pandas automatically parsing dates\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35c5c515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ride_id                object\n",
       "rideable_type          object\n",
       "started_at             object\n",
       "ended_at               object\n",
       "start_station_name     object\n",
       "start_station_id       object\n",
       "end_station_name       object\n",
       "end_station_id         object\n",
       "start_lat             float64\n",
       "start_lng             float64\n",
       "end_lat               float64\n",
       "end_lng               float64\n",
       "member_casual          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b4986d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: 1052451, columns: 13\n"
     ]
    }
   ],
   "source": [
    "rows, cols = df.shape\n",
    "print(f\"rows: {rows}, columns: {cols}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d1ae1b",
   "metadata": {},
   "source": [
    "## Check whether this station is located in Manhattan\n",
    "- start_in_manhattan: If or not the start point is in Manhattan.\n",
    "- end_in_manhattan: whether the end point is in Manhattan \n",
    "- out_of_manhattan: At least one end of it isn't in Manhattan.\n",
    "- A value of 1 means it is in Manhattan, 0 means it is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee956537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Manhattan bounding box\n",
    "lat_min, lat_max = 40.700, 40.880\n",
    "lng_min, lng_max = -74.020, -73.910\n",
    "\n",
    "# Check if start or end station is in Manhattan\n",
    "df['start_in_manhattan'] = (\n",
    "    (df['start_lat'].between(lat_min, lat_max)) &\n",
    "    (df['start_lng'].between(lng_min, lng_max))\n",
    ").astype(int)\n",
    "\n",
    "df['end_in_manhattan'] = (\n",
    "    (df['end_lat'].between(lat_min, lat_max)) &\n",
    "    (df['end_lng'].between(lng_min, lng_max))\n",
    ").astype(int)\n",
    "\n",
    "df['out_of_manhattan'] = 1 - (\n",
    "    df['start_in_manhattan'] & df['end_in_manhattan']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bb6867",
   "metadata": {},
   "source": [
    "## Clean started_at and ended at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f459a81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert started_at column to datetime type\n",
    "df['started_at_parsed'] = pd.to_datetime(df['started_at'], errors='coerce')\n",
    "\n",
    "# extract year, month, and day from the started_at_parsed column\n",
    "df['Started_Year'] = df['started_at_parsed'].dt.year\n",
    "df['Started_Month'] = df['started_at_parsed'].dt.month\n",
    "df['Started_Day'] = df['started_at_parsed'].dt.day\n",
    "df['Started_Hour'] = df['started_at_parsed'].dt.hour\n",
    "\n",
    "# extract season based on the month\n",
    "df['Started_Season'] = df['Started_Month'].map({\n",
    "    12: 'Winter', 1: 'Winter', 2: 'Winter',\n",
    "    3: 'Spring', 4: 'Spring', 5: 'Spring',\n",
    "    6: 'Summer', 7: 'Summer', 8: 'Summer',\n",
    "    9: 'Fall', 10: 'Fall', 11: 'Fall'\n",
    "})\n",
    "\n",
    "# extract weekday name from the started_at_parsed column\n",
    "df['Started_Weekday'] = df['started_at_parsed'].dt.day_name()\n",
    "\n",
    "# df.to_csv('bike_2024_combined_cleaned.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9463b19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert ended_at column to datetime type\n",
    "df['ended_at_parsed'] = pd.to_datetime(df['ended_at'], errors='coerce')\n",
    "\n",
    "# extract year, month, and day from the ended_at_parsed column\n",
    "df['Ended_Year'] = df['ended_at_parsed'].dt.year\n",
    "df['Ended_Month'] = df['ended_at_parsed'].dt.month\n",
    "df['Ended_Day'] = df['ended_at_parsed'].dt.day\n",
    "df['Ended_Hour'] = df['ended_at_parsed'].dt.hour\n",
    "\n",
    "# extract season based on the month\n",
    "df['Ended_Season'] = df['Ended_Month'].map({\n",
    "    12: 'Winter', 1: 'Winter', 2: 'Winter',\n",
    "    3: 'Spring', 4: 'Spring', 5: 'Spring',\n",
    "    6: 'Summer', 7: 'Summer', 8: 'Summer',\n",
    "    9: 'Fall', 10: 'Fall', 11: 'Fall'\n",
    "})\n",
    "\n",
    "# extract weekday name from the ended_at_parsed column\n",
    "df['Ended_Weekday'] = df['ended_at_parsed'].dt.day_name()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82ce450e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ride_id                       object\n",
       "rideable_type                 object\n",
       "started_at                    object\n",
       "ended_at                      object\n",
       "start_station_name            object\n",
       "start_station_id              object\n",
       "end_station_name              object\n",
       "end_station_id                object\n",
       "start_lat                    float64\n",
       "start_lng                    float64\n",
       "end_lat                      float64\n",
       "end_lng                      float64\n",
       "member_casual                 object\n",
       "start_in_manhattan             int64\n",
       "end_in_manhattan               int64\n",
       "out_of_manhattan               int64\n",
       "started_at_parsed     datetime64[ns]\n",
       "Started_Year                 float64\n",
       "Started_Month                float64\n",
       "Started_Day                  float64\n",
       "Started_Hour                 float64\n",
       "Started_Season                object\n",
       "Started_Weekday               object\n",
       "ended_at_parsed       datetime64[ns]\n",
       "Ended_Year                   float64\n",
       "Ended_Month                  float64\n",
       "Ended_Day                    float64\n",
       "Ended_Hour                   float64\n",
       "Ended_Season                  object\n",
       "Ended_Weekday                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02951ac1",
   "metadata": {},
   "source": [
    "## Clean rideable_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07a9277a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['electric_bike', 'classic_bike']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rideable_type'].dropna().unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a10ce8b",
   "metadata": {},
   "source": [
    "## clean station_name and station_id "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4886bf8f",
   "metadata": {},
   "source": [
    "### check the exception values of clean start_station_name and start_station_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0b3dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['start_station_name'].dropna().unique().tolist()\n",
    "# sorted(df['start_station_name'].dropna().unique().tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "879f0658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['start_station_id'].dropna().unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9c213e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station names linked to multiple IDs:\n",
      "Empty DataFrame\n",
      "Columns: [start_station_name, start_station_id]\n",
      "Index: []\n",
      "\n",
      "Station IDs linked to multiple names:\n",
      "Empty DataFrame\n",
      "Columns: [start_station_id, start_station_name]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Find station names linked to multiple IDs ---\n",
    "name_to_ids = df.groupby('start_station_name')['start_station_id'].nunique()\n",
    "conflict_names = name_to_ids[name_to_ids > 1]\n",
    "\n",
    "# --- Step 2: Find station IDs linked to multiple names ---\n",
    "id_to_names = df.groupby('start_station_id')['start_station_name'].nunique()\n",
    "conflict_ids = id_to_names[id_to_names > 1]\n",
    "\n",
    "# --- Step 3: Print mismatched name → ID mappings ---\n",
    "print(\"Station names linked to multiple IDs:\")\n",
    "print(df[df['start_station_name'].isin(conflict_names.index)][['start_station_name', 'start_station_id']].drop_duplicates())\n",
    "\n",
    "# --- Step 4: Print mismatched ID → name mappings ---\n",
    "print(\"\\nStation IDs linked to multiple names:\")\n",
    "print(df[df['start_station_id'].isin(conflict_ids.index)][['start_station_id', 'start_station_name']].drop_duplicates())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b1dab5",
   "metadata": {},
   "source": [
    "### check the exception values of end_station_name and end_station_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63778563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['end_station_name'].dropna().unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bf06fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['end_station_id'].dropna().unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96be3dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End station names linked to multiple IDs:\n",
      "          end_station_name end_station_id\n",
      "123816  E 17 St & Broadway        5980.07\n",
      "180093     W 54 St & 9 Ave        6920.03\n",
      "671474     W 54 St & 9 Ave        6920.05\n",
      "822560  E 17 St & Broadway        5980.10\n",
      "\n",
      "End station IDs linked to multiple names:\n",
      "       end_station_id           end_station_name\n",
      "114909        5772.05  Morton St & Washington St\n",
      "906473        5772.05   Morton St & Greenwich St\n"
     ]
    }
   ],
   "source": [
    "# --- Step 5: Find end station names linked to multiple IDs ---\n",
    "end_name_to_ids = df.groupby('end_station_name')['end_station_id'].nunique()\n",
    "end_conflict_names = end_name_to_ids[end_name_to_ids > 1]\n",
    "\n",
    "# --- Step 6: Find end station IDs linked to multiple names ---\n",
    "end_id_to_names = df.groupby('end_station_id')['end_station_name'].nunique()\n",
    "end_conflict_ids = end_id_to_names[end_id_to_names > 1]\n",
    "\n",
    "# --- Step 7: Print mismatched end name → ID mappings ---\n",
    "print(\"\\nEnd station names linked to multiple IDs:\")\n",
    "print(df[df['end_station_name'].isin(end_conflict_names.index)][['end_station_name', 'end_station_id']].drop_duplicates())\n",
    "\n",
    "# --- Step 8: Print mismatched end ID → name mappings ---\n",
    "print(\"\\nEnd station IDs linked to multiple names:\")\n",
    "print(df[df['end_station_id'].isin(end_conflict_ids.index)][['end_station_id', 'end_station_name']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b32c2b7",
   "metadata": {},
   "source": [
    "### clean those stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c781d8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert station IDs to string for safe comparison\n",
    "df['start_station_id'] = df['start_station_id'].astype(str)\n",
    "df['end_station_id'] = df['end_station_id'].astype(str)\n",
    "\n",
    "# Normalize station names for known issues\n",
    "replace_dict = {\n",
    "    'W 180 St & Ft Washington Ave': 'W 180 St & Fort Washington Ave',\n",
    "    'Morton St & Greenwich St': 'Morton St & Washington St',\n",
    "    'Central Park W & W 76 St': 'Central Park West & W 76 St',\n",
    "    'Monmouth & 6th': 'Monmouth and 6th'\n",
    "}\n",
    "df['start_station_name'] = df['start_station_name'].replace(replace_dict)\n",
    "df['end_station_name'] = df['end_station_name'].replace(replace_dict)\n",
    "\n",
    "# For station names mapped to multiple IDs: keep smallest by string order\n",
    "start_name_to_id = (\n",
    "    df.groupby('start_station_name')['start_station_id']\n",
    "    .apply(lambda x: sorted(x.unique())[0])\n",
    ")\n",
    "end_name_to_id = (\n",
    "    df.groupby('end_station_name')['end_station_id']\n",
    "    .apply(lambda x: sorted(x.unique())[0])\n",
    ")\n",
    "\n",
    "df['start_station_id'] = df['start_station_name'].map(start_name_to_id)\n",
    "df['end_station_id'] = df['end_station_name'].map(end_name_to_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b7e3dc",
   "metadata": {},
   "source": [
    "### check whether exceptions still exist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cad287ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station names linked to multiple IDs:\n",
      "Empty DataFrame\n",
      "Columns: [start_station_name, start_station_id]\n",
      "Index: []\n",
      "\n",
      "Station IDs linked to multiple names:\n",
      "Empty DataFrame\n",
      "Columns: [start_station_id, start_station_name]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Find station names linked to multiple IDs ---\n",
    "name_to_ids = df.groupby('start_station_name')['start_station_id'].nunique()\n",
    "conflict_names = name_to_ids[name_to_ids > 1]\n",
    "\n",
    "# --- Step 2: Find station IDs linked to multiple names ---\n",
    "id_to_names = df.groupby('start_station_id')['start_station_name'].nunique()\n",
    "conflict_ids = id_to_names[id_to_names > 1]\n",
    "\n",
    "# --- Step 3: Print mismatched name → ID mappings ---\n",
    "print(\"Station names linked to multiple IDs:\")\n",
    "print(df[df['start_station_name'].isin(conflict_names.index)][['start_station_name', 'start_station_id']].drop_duplicates())\n",
    "\n",
    "# --- Step 4: Print mismatched ID → name mappings ---\n",
    "print(\"\\nStation IDs linked to multiple names:\")\n",
    "print(df[df['start_station_id'].isin(conflict_ids.index)][['start_station_id', 'start_station_name']].drop_duplicates())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74fee7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End station names linked to multiple IDs:\n",
      "Empty DataFrame\n",
      "Columns: [end_station_name, end_station_id]\n",
      "Index: []\n",
      "\n",
      "End station IDs linked to multiple names:\n",
      "Empty DataFrame\n",
      "Columns: [end_station_id, end_station_name]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# --- Step 5: Find end station names linked to multiple IDs ---\n",
    "end_name_to_ids = df.groupby('end_station_name')['end_station_id'].nunique()\n",
    "end_conflict_names = end_name_to_ids[end_name_to_ids > 1]\n",
    "\n",
    "# --- Step 6: Find end station IDs linked to multiple names ---\n",
    "end_id_to_names = df.groupby('end_station_id')['end_station_name'].nunique()\n",
    "end_conflict_ids = end_id_to_names[end_id_to_names > 1]\n",
    "\n",
    "# --- Step 7: Print mismatched end name → ID mappings ---\n",
    "print(\"\\nEnd station names linked to multiple IDs:\")\n",
    "print(df[df['end_station_name'].isin(end_conflict_names.index)][['end_station_name', 'end_station_id']].drop_duplicates())\n",
    "\n",
    "# --- Step 8: Print mismatched end ID → name mappings ---\n",
    "print(\"\\nEnd station IDs linked to multiple names:\")\n",
    "print(df[df['end_station_id'].isin(end_conflict_ids.index)][['end_station_id', 'end_station_name']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ca6a471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ride_id                       object\n",
       "rideable_type                 object\n",
       "started_at                    object\n",
       "ended_at                      object\n",
       "start_station_name            object\n",
       "start_station_id              object\n",
       "end_station_name              object\n",
       "end_station_id                object\n",
       "start_lat                    float64\n",
       "start_lng                    float64\n",
       "end_lat                      float64\n",
       "end_lng                      float64\n",
       "member_casual                 object\n",
       "start_in_manhattan             int64\n",
       "end_in_manhattan               int64\n",
       "out_of_manhattan               int64\n",
       "started_at_parsed     datetime64[ns]\n",
       "Started_Year                 float64\n",
       "Started_Month                float64\n",
       "Started_Day                  float64\n",
       "Started_Hour                 float64\n",
       "Started_Season                object\n",
       "Started_Weekday               object\n",
       "ended_at_parsed       datetime64[ns]\n",
       "Ended_Year                   float64\n",
       "Ended_Month                  float64\n",
       "Ended_Day                    float64\n",
       "Ended_Hour                   float64\n",
       "Ended_Season                  object\n",
       "Ended_Weekday                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703e5c0b",
   "metadata": {},
   "source": [
    "# calculate busyness by station-hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68026cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     station_id                     station_name\n",
      "1       4074.14       Classon Ave & St Marks Ave\n",
      "1606    4829.01  Columbia Heights & Cranberry St\n",
      "572     4846.01          South St & Whitehall St\n",
      "77      4883.03            Broadway & Whipple St\n",
      "2299    4895.03                Front St & Jay St\n",
      "...         ...                              ...\n",
      "501     8381.04          W 181 St & Riverside Dr\n",
      "1556    8399.06   Fort Washington Ave & W 183 St\n",
      "238     8715.06              W 218 St & Broadway\n",
      "448       HB201             12 St & Sinatra Dr N\n",
      "17        HB611                  4 St & River St\n",
      "\n",
      "[394 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 提取起点在曼哈顿的站点\n",
    "start_stations = df[df['start_in_manhattan'] == 1][['start_station_id', 'start_station_name']]\n",
    "start_stations = start_stations.rename(columns={\n",
    "    'start_station_id': 'station_id',\n",
    "    'start_station_name': 'station_name'\n",
    "})\n",
    "\n",
    "# 提取终点在曼哈顿的站点\n",
    "end_stations = df[df['end_in_manhattan'] == 1][['end_station_id', 'end_station_name']]\n",
    "end_stations = end_stations.rename(columns={\n",
    "    'end_station_id': 'station_id',\n",
    "    'end_station_name': 'station_name'\n",
    "})\n",
    "\n",
    "# 合并并去重\n",
    "stations_in_manhattan = pd.concat([start_stations, end_stations], ignore_index=True)\n",
    "stations_in_manhattan = stations_in_manhattan.dropna().drop_duplicates().sort_values(by='station_id')\n",
    "\n",
    "# 打印所有在曼哈顿的唯一站点\n",
    "print(stations_in_manhattan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48818d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  station_id           timestamp  outflow  inflow\n",
      "0    3431.02 2024-02-14 09:00:00        0       1\n",
      "1    4074.14 2024-02-14 08:00:00        1       0\n",
      "2    4846.01 2024-05-26 13:00:00        0       2\n",
      "3    4883.03 2024-01-24 17:00:00        0       1\n",
      "4    4927.04 2024-04-04 17:00:00        0       1\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Filter trips where at least one end is in Manhattan\n",
    "df_mh = df[(df['start_in_manhattan'] == 1) | (df['end_in_manhattan'] == 1)].copy()\n",
    "\n",
    "# Step 2: Extract hourly timestamps\n",
    "df_mh['Started_Timestamp'] = pd.to_datetime(df_mh['started_at_parsed']).dt.floor('h')\n",
    "df_mh['Ended_Timestamp'] = pd.to_datetime(df_mh['ended_at_parsed']).dt.floor('h')\n",
    "\n",
    "# Step 3: Count outflow by (start_station_id, Started_Timestamp)\n",
    "outflow = (\n",
    "    df_mh.groupby(['start_station_id', 'Started_Timestamp'])\n",
    "    .size()\n",
    "    .reset_index(name='outflow')\n",
    "    .rename(columns={'start_station_id': 'station_id', 'Started_Timestamp': 'timestamp'})\n",
    ")\n",
    "\n",
    "# Step 4: Count inflow by (end_station_id, Ended_Timestamp)\n",
    "inflow = (\n",
    "    df_mh.groupby(['end_station_id', 'Ended_Timestamp'])\n",
    "    .size()\n",
    "    .reset_index(name='inflow')\n",
    "    .rename(columns={'end_station_id': 'station_id', 'Ended_Timestamp': 'timestamp'})\n",
    ")\n",
    "\n",
    "# Step 5: Merge inflow and outflow on (station_id, timestamp)\n",
    "busyness = pd.merge(outflow, inflow, on=['station_id', 'timestamp'], how='outer').fillna(0)\n",
    "\n",
    "# Step 6: Optional - convert counts to integers\n",
    "busyness['inflow'] = busyness['inflow'].astype(int)\n",
    "busyness['outflow'] = busyness['outflow'].astype(int)\n",
    "\n",
    "# Step 7: Save if needed\n",
    "busyness.to_csv(\"manhattan_station_busyness.csv\", index=False)\n",
    "\n",
    "# Preview\n",
    "print(busyness.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "478b9b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  station_id  hour  outflow  inflow\n",
      "0    4074.14     8        1       0\n",
      "1    4846.01    13        0       2\n",
      "2    4883.03    17        0       1\n",
      "3    4927.04    17        0       1\n",
      "4    4939.07    13        0       1\n"
     ]
    }
   ],
   "source": [
    "# Filter for trips with either end in Manhattan\n",
    "df_mh = df[(df['start_in_manhattan'] == 1) | (df['end_in_manhattan'] == 1)].copy()\n",
    "\n",
    "# Drop rows with missing hour values\n",
    "df_mh = df_mh.dropna(subset=['Started_Hour', 'Ended_Hour'])\n",
    "\n",
    "# Ensure hour columns are integer\n",
    "df_mh['Started_Hour'] = df_mh['Started_Hour'].astype(int)\n",
    "df_mh['Ended_Hour'] = df_mh['Ended_Hour'].astype(int)\n",
    "\n",
    "# Group and count outflow\n",
    "outflow = df_mh[df_mh['start_in_manhattan'] == 1].groupby(\n",
    "    ['start_station_id', 'Started_Hour']\n",
    ").size().reset_index(name='outflow').rename(\n",
    "    columns={'start_station_id': 'station_id', 'Started_Hour': 'hour'}\n",
    ")\n",
    "\n",
    "# Group and count inflow\n",
    "inflow = df_mh[df_mh['end_in_manhattan'] == 1].groupby(\n",
    "    ['end_station_id', 'Ended_Hour']\n",
    ").size().reset_index(name='inflow').rename(\n",
    "    columns={'end_station_id': 'station_id', 'Ended_Hour': 'hour'}\n",
    ")\n",
    "\n",
    "# Merge inflow and outflow\n",
    "busyness = pd.merge(outflow, inflow, on=['station_id', 'hour'], how='outer').fillna(0)\n",
    "busyness[['inflow', 'outflow']] = busyness[['inflow', 'outflow']].astype(int)\n",
    "busyness = busyness.sort_values(by=['station_id', 'hour'])\n",
    "\n",
    "busyness.to_csv(\"manhattan_station_busyness_hour.csv\", index=False)\n",
    "\n",
    "# Preview\n",
    "print(busyness.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69afc91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"bike_2024_combined_cleaned.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp47350py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
