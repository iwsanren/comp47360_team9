{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "450d7e06",
   "metadata": {},
   "source": [
    "# 02 - Manhattan Weather Data Cleaning and Preprocessing\n",
    "*Weather Data Preparation for Subway Ridership Prediction*\n",
    "\n",
    "---\n",
    "\n",
    "### **Objective**\n",
    "Clean and preprocess 2024 Manhattan hourly weather data to prepare for integration with subway ridership data.\n",
    "\n",
    "---\n",
    "\n",
    "### **Data Source**\n",
    "- **Source:** [OpenWeather](https://openweathermap.org/)\n",
    "- **Location:** Manhattan (approx. lat: 40.77, lon: -73.98)\n",
    "- **File:** `weather_data.csv`\n",
    "- **Path:** `../data/raw/weather_data.csv`\n",
    "- **Format:** CSV\n",
    "- **Units:** Metric\n",
    "\n",
    "---\n",
    "\n",
    "### **Data Range**\n",
    "- **Start:** 2023-12-31\n",
    "- **End:** 2025-01-01\n",
    "- **Total Records:** 9,597\n",
    "- **Total Columns:** 28\n",
    "\n",
    "---\n",
    "\n",
    "### **Weather Parameters Included**\n",
    "- Temperature: `temp`, `temp_min`, `temp_max`, `feels_like`, `dew_point`\n",
    "- Atmosphere: `pressure`, `humidity`, `visibility`, `clouds_all`\n",
    "- Precipitation: `rain_1h`, `snow_1h`\n",
    "- Conditions: `weather_main`, `weather_description`, `weather_icon`\n",
    "- Wind: `wind_speed`, `wind_deg`, `wind_gust`\n",
    "\n",
    "---\n",
    "\n",
    "### **Processing Requirements**\n",
    "- Convert timestamps from **UTC to Eastern Time**, accounting for **Daylight Saving Time (DST)**\n",
    "- Ensure 2024 data is extracted, cleaned, and **hourly complete**\n",
    "- Remove or aggregate duplicate timestamps (especially during DST transitions)\n",
    "- Export cleaned data to: `../data/processed/weather_data_cleaned.parquet`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c70abb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan Weather Data Cleaning and Preprocessing\n",
      "============================================================\n",
      "Analysis Date: 2025-07-28 19:45:12\n",
      "Objective: Clean weather data for ridership prediction\n",
      "============================================================\n",
      "\n",
      "Path Verification\n",
      "------------------------------------------------------------\n",
      "Raw weather file:      C:\\Users\\neasa\\manhattan-subway\\data\\raw\\weather_data.csv\n",
      "Cleaned output file:   C:\\Users\\neasa\\manhattan-subway\\data\\processed\\weather_data_cleaned.parquet\n",
      "Quality report file:   C:\\Users\\neasa\\manhattan-subway\\data\\processed\\weather_data_quality_assessment.json\n",
      "RAW_DIR exists:        True\n",
      "WEATHER_FILE exists:   True\n",
      "\n",
      "Files in RAW_DIR matching '*weather*.csv':\n",
      "  - weather_data.csv\n"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# Setup and Directory Configuration\n",
    "# =============================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plot and display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Log start\n",
    "print(\"Manhattan Weather Data Cleaning and Preprocessing\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"Objective: Clean weather data for ridership prediction\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# =============================\n",
    "# Directory and File Configuration\n",
    "# =============================\n",
    "\n",
    "# Assumes this notebook is inside `notebooks/`\n",
    "PROJECT_DIR = Path.cwd().resolve().parents[0]\n",
    "DATA_DIR = PROJECT_DIR / \"data\"\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# File paths\n",
    "WEATHER_FILE = RAW_DIR / \"weather_data.csv\"\n",
    "CLEANED_PARQUET = PROCESSED_DIR / \"weather_data_cleaned.parquet\"\n",
    "QUALITY_REPORT = PROCESSED_DIR / \"weather_data_quality_assessment.json\"\n",
    "\n",
    "# Constants\n",
    "EXPECTED_HOURS_2024 = 8784\n",
    "NYC_TIMEZONE = pytz.timezone(\"America/New_York\")\n",
    "\n",
    "# Verify path setup\n",
    "print(\"\\nPath Verification\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Raw weather file:      {WEATHER_FILE}\")\n",
    "print(f\"Cleaned output file:   {CLEANED_PARQUET}\")\n",
    "print(f\"Quality report file:   {QUALITY_REPORT}\")\n",
    "print(f\"RAW_DIR exists:        {RAW_DIR.exists()}\")\n",
    "print(f\"WEATHER_FILE exists:   {WEATHER_FILE.exists()}\")\n",
    "\n",
    "if RAW_DIR.exists():\n",
    "    print(\"\\nFiles in RAW_DIR matching '*weather*.csv':\")\n",
    "    for file in RAW_DIR.glob(\"*weather*.csv\"):\n",
    "        print(f\"  - {file.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b309d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "1. LOADING AND EXAMINING WEATHER DATA\n",
      "============================================================\n",
      "Loading weather data from: weather_data.csv\n",
      "Raw weather data loaded successfully\n",
      "Shape: (9597, 28)\n",
      "Columns: 28\n",
      "Memory usage: 4.8 MB\n",
      "\n",
      "Original Columns (28):\n",
      "   1. dt\n",
      "   2. dt_iso\n",
      "   3. timezone\n",
      "   4. city_name\n",
      "   5. lat\n",
      "   6. lon\n",
      "   7. temp\n",
      "   8. visibility\n",
      "   9. dew_point\n",
      "  10. feels_like\n",
      "  11. temp_min\n",
      "  12. temp_max\n",
      "  13. pressure\n",
      "  14. sea_level\n",
      "  15. grnd_level\n",
      "  16. humidity\n",
      "  17. wind_speed\n",
      "  18. wind_deg\n",
      "  19. wind_gust\n",
      "  20. rain_1h\n",
      "  21. rain_3h\n",
      "  22. snow_1h\n",
      "  23. snow_3h\n",
      "  24. clouds_all\n",
      "  25. weather_id\n",
      "  26. weather_main\n",
      "  27. weather_description\n",
      "  28. weather_icon\n",
      "\n",
      "Data types:\n",
      "dt                       int64\n",
      "dt_iso                  object\n",
      "timezone                 int64\n",
      "city_name               object\n",
      "lat                    float64\n",
      "lon                    float64\n",
      "temp                   float64\n",
      "visibility             float64\n",
      "dew_point              float64\n",
      "feels_like             float64\n",
      "temp_min               float64\n",
      "temp_max               float64\n",
      "pressure                 int64\n",
      "sea_level              float64\n",
      "grnd_level             float64\n",
      "humidity                 int64\n",
      "wind_speed             float64\n",
      "wind_deg                 int64\n",
      "wind_gust              float64\n",
      "rain_1h                float64\n",
      "rain_3h                float64\n",
      "snow_1h                float64\n",
      "snow_3h                float64\n",
      "clouds_all               int64\n",
      "weather_id               int64\n",
      "weather_main            object\n",
      "weather_description     object\n",
      "weather_icon            object\n",
      "dtype: object\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>dt_iso</th>\n",
       "      <th>timezone</th>\n",
       "      <th>city_name</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>temp</th>\n",
       "      <th>visibility</th>\n",
       "      <th>dew_point</th>\n",
       "      <th>feels_like</th>\n",
       "      <th>temp_min</th>\n",
       "      <th>temp_max</th>\n",
       "      <th>pressure</th>\n",
       "      <th>sea_level</th>\n",
       "      <th>grnd_level</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_deg</th>\n",
       "      <th>wind_gust</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>rain_3h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>snow_3h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_id</th>\n",
       "      <th>weather_main</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>weather_icon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1703980800</td>\n",
       "      <td>2023-12-31 00:00:00 +0000 UTC</td>\n",
       "      <td>-18000</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>40.768517</td>\n",
       "      <td>-73.982194</td>\n",
       "      <td>6.53</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.26</td>\n",
       "      <td>3.19</td>\n",
       "      <td>5.97</td>\n",
       "      <td>7.08</td>\n",
       "      <td>1007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69</td>\n",
       "      <td>5.14</td>\n",
       "      <td>300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>802</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>scattered clouds</td>\n",
       "      <td>03n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1703984400</td>\n",
       "      <td>2023-12-31 01:00:00 +0000 UTC</td>\n",
       "      <td>-18000</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>40.768517</td>\n",
       "      <td>-73.982194</td>\n",
       "      <td>5.81</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>1.16</td>\n",
       "      <td>4.87</td>\n",
       "      <td>6.20</td>\n",
       "      <td>1008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63</td>\n",
       "      <td>8.23</td>\n",
       "      <td>300</td>\n",
       "      <td>11.32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75</td>\n",
       "      <td>803</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>04n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1703988000</td>\n",
       "      <td>2023-12-31 02:00:00 +0000 UTC</td>\n",
       "      <td>-18000</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>40.768517</td>\n",
       "      <td>-73.982194</td>\n",
       "      <td>5.45</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>-1.49</td>\n",
       "      <td>1.83</td>\n",
       "      <td>4.49</td>\n",
       "      <td>6.08</td>\n",
       "      <td>1008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60</td>\n",
       "      <td>5.14</td>\n",
       "      <td>320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>Clear</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>01n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1703991600</td>\n",
       "      <td>2023-12-31 03:00:00 +0000 UTC</td>\n",
       "      <td>-18000</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>40.768517</td>\n",
       "      <td>-73.982194</td>\n",
       "      <td>4.92</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>-1.54</td>\n",
       "      <td>1.17</td>\n",
       "      <td>3.44</td>\n",
       "      <td>5.86</td>\n",
       "      <td>1009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62</td>\n",
       "      <td>5.14</td>\n",
       "      <td>310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>Clear</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>01n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1703995200</td>\n",
       "      <td>2023-12-31 04:00:00 +0000 UTC</td>\n",
       "      <td>-18000</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>40.768517</td>\n",
       "      <td>-73.982194</td>\n",
       "      <td>4.34</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>-1.46</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.87</td>\n",
       "      <td>4.99</td>\n",
       "      <td>1010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>4.63</td>\n",
       "      <td>310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75</td>\n",
       "      <td>803</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>04n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt                         dt_iso  timezone  city_name        lat  \\\n",
       "0  1703980800  2023-12-31 00:00:00 +0000 UTC    -18000  Manhattan  40.768517   \n",
       "1  1703984400  2023-12-31 01:00:00 +0000 UTC    -18000  Manhattan  40.768517   \n",
       "2  1703988000  2023-12-31 02:00:00 +0000 UTC    -18000  Manhattan  40.768517   \n",
       "3  1703991600  2023-12-31 03:00:00 +0000 UTC    -18000  Manhattan  40.768517   \n",
       "4  1703995200  2023-12-31 04:00:00 +0000 UTC    -18000  Manhattan  40.768517   \n",
       "\n",
       "         lon  temp  visibility  dew_point  feels_like  temp_min  temp_max  \\\n",
       "0 -73.982194  6.53     10000.0       1.26        3.19      5.97      7.08   \n",
       "1 -73.982194  5.81     10000.0      -0.60        1.16      4.87      6.20   \n",
       "2 -73.982194  5.45     10000.0      -1.49        1.83      4.49      6.08   \n",
       "3 -73.982194  4.92     10000.0      -1.54        1.17      3.44      5.86   \n",
       "4 -73.982194  4.34     10000.0      -1.46        0.70      2.87      4.99   \n",
       "\n",
       "   pressure  sea_level  grnd_level  humidity  wind_speed  wind_deg  wind_gust  \\\n",
       "0      1007        NaN         NaN        69        5.14       300        NaN   \n",
       "1      1008        NaN         NaN        63        8.23       300      11.32   \n",
       "2      1008        NaN         NaN        60        5.14       320        NaN   \n",
       "3      1009        NaN         NaN        62        5.14       310        NaN   \n",
       "4      1010        NaN         NaN        65        4.63       310        NaN   \n",
       "\n",
       "   rain_1h  rain_3h  snow_1h  snow_3h  clouds_all  weather_id weather_main  \\\n",
       "0      NaN      NaN      NaN      NaN          40         802       Clouds   \n",
       "1      NaN      NaN      NaN      NaN          75         803       Clouds   \n",
       "2      NaN      NaN      NaN      NaN           0         800        Clear   \n",
       "3      NaN      NaN      NaN      NaN           0         800        Clear   \n",
       "4      NaN      NaN      NaN      NaN          75         803       Clouds   \n",
       "\n",
       "  weather_description weather_icon  \n",
       "0    scattered clouds          03n  \n",
       "1       broken clouds          04n  \n",
       "2        sky is clear          01n  \n",
       "3        sky is clear          01n  \n",
       "4       broken clouds          04n  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quick quality overview:\n",
      "• Date range: 2023-12-31 00:00:00 +0000 UTC to 2025-01-01 23:00:00 +0000 UTC\n",
      "• Duplicate rows: 0\n",
      "• Missing values: 60848 total\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"1. LOADING AND EXAMINING WEATHER DATA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Confirm weather file exists\n",
    "if not WEATHER_FILE.exists():\n",
    "    raise FileNotFoundError(f\"Weather data file not found: {WEATHER_FILE}\")\n",
    "\n",
    "print(f\"Loading weather data from: {WEATHER_FILE.name}\")\n",
    "weather_df = pd.read_csv(WEATHER_FILE)\n",
    "\n",
    "print(\"Raw weather data loaded successfully\")\n",
    "print(f\"Shape: {weather_df.shape}\")\n",
    "print(f\"Columns: {len(weather_df.columns)}\")\n",
    "print(f\"Memory usage: {weather_df.memory_usage(deep=True).sum() / (1024**2):.1f} MB\")\n",
    "\n",
    "# Display column names\n",
    "print(f\"\\nOriginal Columns ({len(weather_df.columns)}):\")\n",
    "for i, col in enumerate(weather_df.columns, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "# Dtypes\n",
    "print(\"\\nData types:\")\n",
    "print(weather_df.dtypes)\n",
    "\n",
    "# Sample rows\n",
    "print(\"\\nFirst few rows:\")\n",
    "display(weather_df.head())\n",
    "\n",
    "# Basic data quality check\n",
    "print(\"\\nQuick quality overview:\")\n",
    "print(f\"• Date range: {weather_df['dt_iso'].iloc[0]} to {weather_df['dt_iso'].iloc[-1]}\")\n",
    "print(f\"• Duplicate rows: {weather_df.duplicated().sum()}\")\n",
    "print(f\"• Missing values: {weather_df.isnull().sum().sum()} total\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d980f1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "2. DATA QUALITY ASSESSMENT & TEMPORAL CHECK\n",
      "============================================================\n",
      "\n",
      "Missing values per column:\n",
      "visibility      20\n",
      "sea_level     9597\n",
      "grnd_level    9597\n",
      "wind_gust     5668\n",
      "rain_1h       7539\n",
      "rain_3h       9332\n",
      "snow_1h       9510\n",
      "snow_3h       9585\n",
      "dtype: int64\n",
      "\n",
      "Total missing values: 60,848\n",
      "\n",
      "Duplicate rows: 0\n",
      "\n",
      "Parsing UTC timestamps from 'dt_iso'...\n",
      "Fallback applied: removed ' UTC' and parsed as UTC.\n",
      "Parsed date range: 2023-12-31 00:00:00+00:00 to 2025-01-01 23:00:00+00:00\n",
      "Total records: 9,597\n",
      "\n",
      "Checking for irregular time gaps...\n",
      "Found 765 irregular gaps (non-hourly spacing)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"2. DATA QUALITY ASSESSMENT & TEMPORAL CHECK\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# -----------------------------\n",
    "# Missing data per column\n",
    "# -----------------------------\n",
    "print(\"\\nMissing values per column:\")\n",
    "missing_counts = weather_df.isnull().sum()\n",
    "missing_cols = missing_counts[missing_counts > 0]\n",
    "\n",
    "if not missing_cols.empty:\n",
    "    print(missing_cols)\n",
    "    print(f\"\\nTotal missing values: {missing_counts.sum():,}\")\n",
    "else:\n",
    "    print(\"No missing values found.\")\n",
    "\n",
    "# -----------------------------\n",
    "# Duplicate row check\n",
    "# -----------------------------\n",
    "duplicate_count = weather_df.duplicated().sum()\n",
    "print(f\"\\nDuplicate rows: {duplicate_count}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Parse timestamps from 'dt_iso'\n",
    "# -----------------------------\n",
    "print(\"\\nParsing UTC timestamps from 'dt_iso'...\")\n",
    "\n",
    "try:\n",
    "    weather_df['dt_iso_temp'] = pd.to_datetime(weather_df['dt_iso'], format='%Y-%m-%d %H:%M:%S %z %Z')\n",
    "    print(\"Parsed using timezone-aware format.\")\n",
    "except Exception:\n",
    "    dt_iso_clean = weather_df['dt_iso'].str.replace(' UTC', '', regex=False)\n",
    "    weather_df['dt_iso_temp'] = pd.to_datetime(dt_iso_clean, utc=True)\n",
    "    print(\"Fallback applied: removed ' UTC' and parsed as UTC.\")\n",
    "\n",
    "# -----------------------------\n",
    "# Check date range and gaps\n",
    "# -----------------------------\n",
    "min_ts = weather_df['dt_iso_temp'].min()\n",
    "max_ts = weather_df['dt_iso_temp'].max()\n",
    "\n",
    "print(f\"Parsed date range: {min_ts} to {max_ts}\")\n",
    "print(f\"Total records: {len(weather_df):,}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Temporal gap check (should be hourly)\n",
    "# -----------------------------\n",
    "print(\"\\nChecking for irregular time gaps...\")\n",
    "time_deltas = weather_df['dt_iso_temp'].diff().dropna()\n",
    "expected_gap = pd.Timedelta(hours=1)\n",
    "irregular_gaps = time_deltas[time_deltas != expected_gap]\n",
    "\n",
    "if not irregular_gaps.empty:\n",
    "    print(f\"Found {len(irregular_gaps)} irregular gaps (non-hourly spacing)\")\n",
    "else:\n",
    "    print(\"All timestamps are spaced hourly (as expected)\")\n",
    "\n",
    "# -----------------------------\n",
    "# Cleanup temporary column\n",
    "# -----------------------------\n",
    "weather_df.drop(columns='dt_iso_temp', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3ba538e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "2. TIMEZONE CONVERSION (UTC TO EASTERN TIME WITH DST)\n",
      "============================================================\n",
      "Converting UTC timestamps to Eastern Time (handling DST)...\n",
      "Fallback: removing ' UTC' and parsing as UTC...\n",
      "\n",
      "UTC Timestamp Range:\n",
      "  Start: 2023-12-31 00:00:00+00:00\n",
      "  End:   2025-01-01 23:00:00+00:00\n",
      "\n",
      "Eastern Timezone Timestamp Range:\n",
      "  Start: 2023-12-30 19:00:00\n",
      "  End:   2025-01-01 18:00:00\n",
      "\n",
      "Sample conversions:\n",
      "                          dt_iso                    dt_utc   transit_timestamp\n",
      "0  2023-12-31 00:00:00 +0000 UTC 2023-12-31 00:00:00+00:00 2023-12-30 19:00:00\n",
      "1  2023-12-31 01:00:00 +0000 UTC 2023-12-31 01:00:00+00:00 2023-12-30 20:00:00\n",
      "2  2023-12-31 02:00:00 +0000 UTC 2023-12-31 02:00:00+00:00 2023-12-30 21:00:00\n",
      "3  2023-12-31 03:00:00 +0000 UTC 2023-12-31 03:00:00+00:00 2023-12-30 22:00:00\n",
      "4  2023-12-31 04:00:00 +0000 UTC 2023-12-31 04:00:00+00:00 2023-12-30 23:00:00\n",
      "\n",
      "DST transition verification:\n",
      "March sample (DST begins - second Sunday):\n",
      "                             dt_iso   transit_timestamp\n",
      "1647  2024-03-01 05:00:00 +0000 UTC 2024-03-01 00:00:00\n",
      "1648  2024-03-01 06:00:00 +0000 UTC 2024-03-01 01:00:00\n",
      "1649  2024-03-01 07:00:00 +0000 UTC 2024-03-01 02:00:00\n",
      "November sample (DST ends - first Sunday):\n",
      "                             dt_iso   transit_timestamp\n",
      "7953  2024-11-01 04:00:00 +0000 UTC 2024-11-01 00:00:00\n",
      "7954  2024-11-01 05:00:00 +0000 UTC 2024-11-01 01:00:00\n",
      "7955  2024-11-01 06:00:00 +0000 UTC 2024-11-01 02:00:00\n",
      "\n",
      "Timezone conversion completed successfully.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"2. TIMEZONE CONVERSION (UTC TO EASTERN TIME WITH DST)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Parse datetime from 'dt_iso' and localize to Eastern Time\n",
    "print(\"Converting UTC timestamps to Eastern Time (handling DST)...\")\n",
    "\n",
    "try:\n",
    "    # Attempt parsing full timezone-aware string\n",
    "    weather_df['dt_utc'] = pd.to_datetime(weather_df['dt_iso'], format='%Y-%m-%d %H:%M:%S %z %Z')\n",
    "    print(\"Parsed datetime with timezone format successfully.\")\n",
    "except Exception:\n",
    "    print(\"Fallback: removing ' UTC' and parsing as UTC...\")\n",
    "    cleaned_dt = weather_df['dt_iso'].str.replace(' UTC', '', regex=False)\n",
    "    weather_df['dt_utc'] = pd.to_datetime(cleaned_dt, utc=True)\n",
    "\n",
    "# Show UTC range\n",
    "print(f\"\\nUTC Timestamp Range:\")\n",
    "print(f\"  Start: {weather_df['dt_utc'].min()}\")\n",
    "print(f\"  End:   {weather_df['dt_utc'].max()}\")\n",
    "\n",
    "# Convert to NYC time (DST-aware)\n",
    "weather_df['transit_timestamp'] = weather_df['dt_utc'].dt.tz_convert(NYC_TIMEZONE).dt.tz_localize(None)\n",
    "\n",
    "# Show ET range\n",
    "print(f\"\\nEastern Timezone Timestamp Range:\")\n",
    "print(f\"  Start: {weather_df['transit_timestamp'].min()}\")\n",
    "print(f\"  End:   {weather_df['transit_timestamp'].max()}\")\n",
    "\n",
    "# Sample conversions\n",
    "print(\"\\nSample conversions:\")\n",
    "print(weather_df[['dt_iso', 'dt_utc', 'transit_timestamp']].head(5))\n",
    "\n",
    "# DST transition checks\n",
    "print(\"\\nDST transition verification:\")\n",
    "\n",
    "march_sample = weather_df[weather_df['transit_timestamp'].dt.month == 3].head(3)\n",
    "nov_sample = weather_df[weather_df['transit_timestamp'].dt.month == 11].head(3)\n",
    "\n",
    "if not march_sample.empty:\n",
    "    print(\"March sample (DST begins - second Sunday):\")\n",
    "    print(march_sample[['dt_iso', 'transit_timestamp']])\n",
    "\n",
    "if not nov_sample.empty:\n",
    "    print(\"November sample (DST ends - first Sunday):\")\n",
    "    print(nov_sample[['dt_iso', 'transit_timestamp']])\n",
    "\n",
    "print(\"\\nTimezone conversion completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5199db32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verifying summer timestamps (should reflect UTC-4 conversion)...\n",
      "July sample (during Daylight Saving Time - UTC-4):\n",
      "                             dt_iso   transit_timestamp\n",
      "4840  2024-07-01 04:00:00 +0000 UTC 2024-07-01 00:00:00\n",
      "4841  2024-07-01 05:00:00 +0000 UTC 2024-07-01 01:00:00\n",
      "4842  2024-07-01 06:00:00 +0000 UTC 2024-07-01 02:00:00\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------\n",
    "# Verification for Summer Months (e.g. July)\n",
    "# -----------------------------------------------\n",
    "print(\"\\nVerifying summer timestamps (should reflect UTC-4 conversion)...\")\n",
    "\n",
    "july_sample = weather_df[weather_df['transit_timestamp'].dt.month == 7].head(3)\n",
    "\n",
    "if not july_sample.empty:\n",
    "    print(\"July sample (during Daylight Saving Time - UTC-4):\")\n",
    "    print(july_sample[['dt_iso', 'transit_timestamp']])\n",
    "else:\n",
    "    print(\"No July records found in dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e44ecf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "3. FILTER TO 2024 DATA ONLY\n",
      "============================================================\n",
      "Filtering to full-year 2024 window: 2024-01-01 00:00:00 to 2025-01-01 00:00:00\n",
      "\n",
      "Records before filtering: 9,597\n",
      "Records after filtering:  9,549\n",
      "Records removed:          48\n",
      "Filtered date range:      2024-01-01 00:00:00 → 2024-12-31 23:00:00\n",
      "\n",
      "Expected hours (DST adjusted): 8783\n",
      "Actual hourly records:         9549\n",
      "Coverage:                      108.72%\n",
      "Over 100% coverage — likely duplicate timestamps (requires aggregation).\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"3. FILTER TO 2024 DATA ONLY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Define 2024 datetime bounds\n",
    "start_2024 = datetime(2024, 1, 1, 0, 0, 0)\n",
    "end_2024 = datetime(2025, 1, 1, 0, 0, 0)\n",
    "\n",
    "print(f\"Filtering to full-year 2024 window: {start_2024} to {end_2024}\")\n",
    "\n",
    "# Filter to 2024 only\n",
    "weather_2024 = weather_df[\n",
    "    (weather_df['transit_timestamp'] >= start_2024) & \n",
    "    (weather_df['transit_timestamp'] < end_2024)\n",
    "].copy()\n",
    "\n",
    "# Summary\n",
    "print(f\"\\nRecords before filtering: {len(weather_df):,}\")\n",
    "print(f\"Records after filtering:  {len(weather_2024):,}\")\n",
    "print(f\"Records removed:          {len(weather_df) - len(weather_2024):,}\")\n",
    "print(f\"Filtered date range:      {weather_2024['transit_timestamp'].min()} → {weather_2024['transit_timestamp'].max()}\")\n",
    "\n",
    "# DST-aware expected hours (spring forward loses 1 hour)\n",
    "expected_hours_dst = EXPECTED_HOURS_2024 - 1\n",
    "actual_hours = len(weather_2024)\n",
    "coverage_pct = (actual_hours / expected_hours_dst) * 100\n",
    "\n",
    "print(f\"\\nExpected hours (DST adjusted): {expected_hours_dst}\")\n",
    "print(f\"Actual hourly records:         {actual_hours}\")\n",
    "print(f\"Coverage:                      {coverage_pct:.2f}%\")\n",
    "\n",
    "# Coverage assessment\n",
    "if coverage_pct > 100:\n",
    "    print(\"Over 100% coverage — likely duplicate timestamps (requires aggregation).\")\n",
    "elif coverage_pct >= 99:\n",
    "    print(\"Excellent coverage — minimal to no missing data.\")\n",
    "elif coverage_pct >= 95:\n",
    "    print(\"Good coverage — acceptable for modeling.\")\n",
    "elif coverage_pct >= 90:\n",
    "    print(\"Fair coverage — review before model use.\")\n",
    "else:\n",
    "    print(\"Low coverage — major data gaps, not recommended for modeling.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a21dc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "4. HANDLE DUPLICATE TIMESTAMPS\n",
      "============================================================\n",
      "Duplicate timestamps found: 766\n",
      "Resolving duplicates using aggregation...\n",
      "Sample duplicated timestamps:\n",
      "transit_timestamp\n",
      "2024-02-13 05:00:00    3\n",
      "2024-02-13 06:00:00    3\n",
      "2024-01-24 22:00:00    3\n",
      "2024-01-07 11:00:00    3\n",
      "2024-01-07 12:00:00    3\n",
      "Name: count, dtype: int64\n",
      "Columns being aggregated: 16\n",
      "Cleaned record count: 8,783\n",
      "Duplicates resolved: 766\n",
      "\n",
      "Hourly granularity verification:\n",
      "  Unique minute values: 1\n",
      "  Unique second values: 1\n",
      "Timestamps aligned to hourly (HH:00:00) — granularity confirmed.\n",
      "\n",
      "Final cleaned dataset: 8,783 hourly records\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"4. HANDLE DUPLICATE TIMESTAMPS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check for duplicates\n",
    "duplicate_count = weather_2024['transit_timestamp'].duplicated().sum()\n",
    "print(f\"Duplicate timestamps found: {duplicate_count}\")\n",
    "\n",
    "if duplicate_count > 0:\n",
    "    print(\"Resolving duplicates using aggregation...\")\n",
    "\n",
    "    # Show a few duplicated timestamps\n",
    "    sample_dupes = weather_2024[weather_2024['transit_timestamp'].duplicated(keep=False)]\n",
    "    print(\"Sample duplicated timestamps:\")\n",
    "    print(sample_dupes['transit_timestamp'].value_counts().head())\n",
    "\n",
    "    # Aggregation strategy\n",
    "    aggregation_rules = {\n",
    "        # Core measurements (mean)\n",
    "        'temp': 'mean', 'feels_like': 'mean', 'dew_point': 'mean',\n",
    "        'humidity': 'mean', 'pressure': 'mean', 'visibility': 'mean',\n",
    "        'wind_speed': 'mean', 'wind_deg': 'mean',\n",
    "        'temp_min': 'mean', 'temp_max': 'mean',\n",
    "        'clouds_all': 'mean',\n",
    "\n",
    "        # Precipitation (max for conservative signal)\n",
    "        'rain_1h': 'max', 'snow_1h': 'max',\n",
    "\n",
    "        # Categorical (first valid observation)\n",
    "        'weather_main': 'first', 'weather_description': 'first', 'weather_icon': 'first'\n",
    "    }\n",
    "\n",
    "    # Limit to available columns\n",
    "    available_agg = {col: method for col, method in aggregation_rules.items() if col in weather_2024.columns}\n",
    "    print(f\"Columns being aggregated: {len(available_agg)}\")\n",
    "\n",
    "    # Apply aggregation\n",
    "    weather_clean = (\n",
    "        weather_2024.groupby('transit_timestamp')\n",
    "        .agg(available_agg)\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    print(f\"Cleaned record count: {len(weather_clean):,}\")\n",
    "    print(f\"Duplicates resolved: {len(weather_2024) - len(weather_clean):,}\")\n",
    "\n",
    "else:\n",
    "    print(\"No duplicates detected — using original 2024 data.\")\n",
    "    weather_clean = weather_2024.copy()\n",
    "\n",
    "# Hourly timestamp verification\n",
    "minute_check = weather_clean['transit_timestamp'].dt.minute.nunique()\n",
    "second_check = weather_clean['transit_timestamp'].dt.second.nunique()\n",
    "\n",
    "print(\"\\nHourly granularity verification:\")\n",
    "print(f\"  Unique minute values: {minute_check}\")\n",
    "print(f\"  Unique second values: {second_check}\")\n",
    "\n",
    "if minute_check == 1 and second_check == 1:\n",
    "    print(\"Timestamps aligned to hourly (HH:00:00) — granularity confirmed.\")\n",
    "else:\n",
    "    print(\"Warning: Timestamps not perfectly aligned to hourly boundaries.\")\n",
    "\n",
    "print(f\"\\nFinal cleaned dataset: {len(weather_clean):,} hourly records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eede7179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "5. DATA QUALITY VALIDATION\n",
      "============================================================\n",
      "5.1 TEMPORAL COVERAGE VALIDATION\n",
      "----------------------------------------\n",
      "Expected hourly records (with DST): 8783\n",
      "Actual hourly records:              8783\n",
      "Coverage percentage:                100.00%\n",
      "Coverage Status: EXCELLENT\n",
      "\n",
      "5.2 FIELD-LEVEL VALIDITY CHECKS\n",
      "----------------------------------------\n",
      "  PASS - No duplicate timestamps\n",
      "  PASS - Temperature within reasonable NYC range (-30°C to 50°C)\n",
      "  PASS - No negative values in rain or snow\n",
      "  PASS - Humidity within 0-100%\n",
      "  PASS - Wind speed within 0-50 m/s\n",
      "  PASS - Visibility within 0-50,000 meters\n",
      "\n",
      "Checks passed: 6/6 (100.0%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"5. DATA QUALITY VALIDATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Initialize result dictionary\n",
    "quality_results = {}\n",
    "\n",
    "# ----------------------------------------\n",
    "# 5.1 Temporal Coverage Validation\n",
    "# ----------------------------------------\n",
    "print(\"5.1 TEMPORAL COVERAGE VALIDATION\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "expected_hours = EXPECTED_HOURS_2024 - 1  # Spring forward removes 1 hour\n",
    "actual_hours = len(weather_clean)\n",
    "coverage_pct = (actual_hours / expected_hours) * 100\n",
    "\n",
    "print(f\"Expected hourly records (with DST): {expected_hours}\")\n",
    "print(f\"Actual hourly records:              {actual_hours}\")\n",
    "print(f\"Coverage percentage:                {coverage_pct:.2f}%\")\n",
    "\n",
    "if coverage_pct >= 99.5:\n",
    "    coverage_status = \"EXCELLENT\"\n",
    "elif coverage_pct >= 95:\n",
    "    coverage_status = \"GOOD\"\n",
    "else:\n",
    "    coverage_status = \"NEEDS REVIEW\"\n",
    "\n",
    "print(f\"Coverage Status: {coverage_status}\")\n",
    "\n",
    "quality_results[\"temporal_coverage\"] = {\n",
    "    \"expected_hours\": expected_hours,\n",
    "    \"actual_hours\": actual_hours,\n",
    "    \"coverage_pct\": coverage_pct,\n",
    "    \"status\": coverage_status\n",
    "}\n",
    "\n",
    "# ----------------------------------------\n",
    "# 5.2 Field-Level Validity Checks\n",
    "# ----------------------------------------\n",
    "print(\"\\n5.2 FIELD-LEVEL VALIDITY CHECKS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Define all checks\n",
    "quality_checks = {\n",
    "    \"no_duplicate_timestamps\": {\n",
    "        \"passed\": weather_clean['transit_timestamp'].duplicated().sum() == 0,\n",
    "        \"description\": \"No duplicate timestamps\"\n",
    "    },\n",
    "    \"reasonable_temperature_celsius\": {\n",
    "        \"passed\": (weather_clean['temp'].min() > -30) and (weather_clean['temp'].max() < 50),\n",
    "        \"description\": \"Temperature within reasonable NYC range (-30°C to 50°C)\"\n",
    "    },\n",
    "    \"non_negative_precipitation\": {\n",
    "        \"passed\": (weather_clean['rain_1h'].fillna(0).min() >= 0) and (weather_clean['snow_1h'].fillna(0).min() >= 0),\n",
    "        \"description\": \"No negative values in rain or snow\"\n",
    "    },\n",
    "    \"reasonable_humidity\": {\n",
    "        \"passed\": (weather_clean['humidity'].min() >= 0) and (weather_clean['humidity'].max() <= 100),\n",
    "        \"description\": \"Humidity within 0-100%\"\n",
    "    },\n",
    "    \"reasonable_wind_speed\": {\n",
    "        \"passed\": (weather_clean['wind_speed'].min() >= 0) and (weather_clean['wind_speed'].max() < 50),\n",
    "        \"description\": \"Wind speed within 0-50 m/s\"\n",
    "    },\n",
    "    \"reasonable_visibility\": {\n",
    "        \"passed\": (weather_clean['visibility'].min() >= 0) and (weather_clean['visibility'].max() <= 50000),\n",
    "        \"description\": \"Visibility within 0-50,000 meters\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Evaluate checks\n",
    "passed_checks = 0\n",
    "for key, check in quality_checks.items():\n",
    "    result = \"PASS\" if check[\"passed\"] else \"FAIL\"\n",
    "    print(f\"  {result:4s} - {check['description']}\")\n",
    "    if check[\"passed\"]:\n",
    "        passed_checks += 1\n",
    "\n",
    "# Store in results\n",
    "quality_results[\"field_checks\"] = {\n",
    "    \"total_checks\": len(quality_checks),\n",
    "    \"passed\": passed_checks,\n",
    "    \"pass_rate\": round((passed_checks / len(quality_checks)) * 100, 1)\n",
    "}\n",
    "\n",
    "print(f\"\\nChecks passed: {passed_checks}/{len(quality_checks)} \"\n",
    "      f\"({quality_results['field_checks']['pass_rate']}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eedc7435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "6. FEATURE SELECTION FOR INTEGRATION\n",
      "============================================================\n",
      "Selecting core weather features for ridership prediction...\n",
      "Selected 13 core features:\n",
      "   1. transit_timestamp\n",
      "   2. temp\n",
      "   3. feels_like\n",
      "   4. dew_point\n",
      "   5. humidity\n",
      "   6. wind_speed\n",
      "   7. pressure\n",
      "   8. visibility\n",
      "   9. rain_1h\n",
      "  10. snow_1h\n",
      "  11. weather_main\n",
      "  12. weather_description\n",
      "  13. clouds_all\n",
      "\n",
      "Integration-ready dataset shape: (8783, 13)\n",
      "\n",
      "Feature categories by type:\n",
      "  • Timestamp    : 1 feature(s)\n",
      "  • Temperature  : 3 feature(s)\n",
      "  • Atmospheric  : 4 feature(s)\n",
      "  • Wind         : 1 feature(s)\n",
      "  • Precipitation: 2 feature(s)\n",
      "  • Conditions   : 2 feature(s)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"6. FEATURE SELECTION FOR INTEGRATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"Selecting core weather features for ridership prediction...\")\n",
    "\n",
    "# Define essential features (safe for modeling and integration)\n",
    "integration_features = [\n",
    "    'transit_timestamp',      # 1\n",
    "    'temp',                   # 2 \n",
    "    'feels_like',             # 3 \n",
    "    'dew_point',              # 4  \n",
    "    'humidity',               # 5\n",
    "    'wind_speed',             # 6\n",
    "    'pressure',               # 7\n",
    "    'visibility',             # 8\n",
    "    'rain_1h',                # 9\n",
    "    'snow_1h',                # 10\n",
    "    'weather_main',           # 11\n",
    "    'weather_description',    # 12\n",
    "    'clouds_all',             # 13\n",
    "]\n",
    "\n",
    "# Filter to columns that exist in cleaned dataset\n",
    "available_features = [col for col in integration_features if col in weather_clean.columns]\n",
    "integration_df = weather_clean[available_features].copy()\n",
    "\n",
    "# Output selection summary\n",
    "print(f\"Selected {len(available_features)} core features:\")\n",
    "for i, col in enumerate(available_features, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "# Preview dataset shape\n",
    "print(f\"\\nIntegration-ready dataset shape: {integration_df.shape}\")\n",
    "\n",
    "# Feature category classification (for readability)\n",
    "feature_categories = {\n",
    "    \"timestamp\": ['transit_timestamp'],\n",
    "    \"temperature\": ['temp', 'feels_like', 'dew_point'],\n",
    "    \"atmospheric\": ['humidity', 'pressure', 'visibility', 'clouds_all'],\n",
    "    \"wind\": ['wind_speed'],\n",
    "    \"precipitation\": ['rain_1h', 'snow_1h'],\n",
    "    \"conditions\": ['weather_main', 'weather_description']\n",
    "}\n",
    "\n",
    "print(f\"\\nFeature categories by type:\")\n",
    "for group, cols in feature_categories.items():\n",
    "    present = [c for c in cols if c in available_features]\n",
    "    if present:\n",
    "        print(f\"  • {group.title():<13}: {len(present)} feature(s)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2231be58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "7. DATA EXPORT AND SUMMARY\n",
      "============================================================\n",
      "Cleaned weather data exported to:\n",
      "  C:\\Users\\neasa\\manhattan-subway\\data\\processed\\weather_data_cleaned.parquet\n",
      "Records exported:   8,783\n",
      "Features exported:  13\n",
      "\n",
      "SUMMARY STATISTICS\n",
      "------------------------------------------------------------\n",
      "Original records:         9,597\n",
      "After 2024 filtering:     9,549\n",
      "After duplicate removal:  8,783\n",
      "Final integration set:    8,783\n",
      "Processing success rate:  91.52%\n",
      "\n",
      "============================================================\n",
      "WEATHER DATA CLEANING COMPLETED SUCCESSFULLY\n",
      "============================================================\n",
      "Next: Integrate with subway ridership data.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"7. DATA EXPORT AND SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Define output file path\n",
    "output_file = PROCESSED_DIR / \"weather_data_cleaned.parquet\"\n",
    "\n",
    "# Export cleaned and filtered weather dataset\n",
    "integration_df.to_parquet(output_file, index=False)\n",
    "\n",
    "# Export confirmation\n",
    "print(f\"Cleaned weather data exported to:\\n  {output_file}\")\n",
    "print(f\"Records exported:   {len(integration_df):,}\")\n",
    "print(f\"Features exported:  {len(integration_df.columns)}\")\n",
    "\n",
    "# Summary stats for tracking processing loss\n",
    "print(\"\\nSUMMARY STATISTICS\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Original records:         {len(weather_df):,}\")\n",
    "print(f\"After 2024 filtering:     {len(weather_2024):,}\")\n",
    "print(f\"After duplicate removal:  {len(weather_clean):,}\")\n",
    "print(f\"Final integration set:    {len(integration_df):,}\")\n",
    "print(f\"Processing success rate:  {(len(integration_df) / len(weather_df)) * 100:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"WEATHER DATA CLEANING COMPLETED SUCCESSFULLY\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Next: Integrate with subway ridership data.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manhattan-subway",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
